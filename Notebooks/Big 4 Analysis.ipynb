{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @Robb08962871 Here is what the #Big4Agenda pro...\n",
       "1        #YesKilifi an environment that fosters dialogu...\n",
       "2        #Big4Agenda DEAR KENYANS THEIR IS NOTHING LIKE...\n",
       "3        #SonkoHelpsTurkana Kenyan nightmares...  This ...\n",
       "4        Below are the services we offer. \\r\\n1.Course ...\n",
       "5        @UKenyatta Lovely to see among schools represe...\n",
       "6        The #big4lies to assist in enriching the dynas...\n",
       "7        #Big4Agenda Is A corruption Agenda to embezzle...\n",
       "8        @UKenyatta I think #Big4Agenda  is not achieva...\n",
       "9        A govt that doesn't feed its populace is autom...\n",
       "10       Towards Achievement of The #Big4Agenda \\r\\n\\r\\...\n",
       "11       @UKenyatta #Big4Agenda is dead, concentrate on...\n",
       "12       @dailynation @WilliamsRuto is a pathetic and n...\n",
       "13       A good example of how throwing money at proble...\n",
       "14       #YouthEmpowermentKe\\r\\nI urge youth to invest ...\n",
       "15       Is like that time 50 Cent bought 200 front sea...\n",
       "16       Investing in nutrition and health is investing...\n",
       "17       President @UKenyatta said the #Big4Agenda prov...\n",
       "18       @UKenyatta I don't think the #Big4Agenda  maxi...\n",
       "19                       @UKenyatta #Big4Agenda is a scam.\n",
       "20       Mr @UKenyatta. We may not realise the #Big4Age...\n",
       "21       My Administration is maximizing opportunities ...\n",
       "22       Instead of #BIG4Agenda,lets have 3;1.Corruptio...\n",
       "23       Dont use the drought as an excuse to  import m...\n",
       "24       Our chairlady @mkarembu interacts with Kenya u...\n",
       "25       U Excellence, spare hanging or life imprisonme...\n",
       "26       Do not be left out. Register today and be part...\n",
       "27       According to our @MOH_Kenya \\r\\nWe have #Big4A...\n",
       "28       What people remember is the Genesis and the en...\n",
       "29       Sometimes, the smallest step in the right dire...\n",
       "                               ...                        \n",
       "14970                                                    0\n",
       "14971                                                    0\n",
       "14972                                                    0\n",
       "14973                                                    0\n",
       "14974                                                    0\n",
       "14975                                                    0\n",
       "14976                                                    0\n",
       "14977                                                    0\n",
       "14978                                                    0\n",
       "14979                                                    0\n",
       "14980                                                    0\n",
       "14981                                                    0\n",
       "14982                                                    0\n",
       "14983                                                    0\n",
       "14984                                                    0\n",
       "14985                                                    0\n",
       "14986                                                    0\n",
       "14987                                                    0\n",
       "14988                                                    0\n",
       "14989                                                    0\n",
       "14990                                                    0\n",
       "14991                                                    0\n",
       "14992                                                    0\n",
       "14993                                                    0\n",
       "14994                                                    0\n",
       "14995                                                    0\n",
       "14996                                                    0\n",
       "14997                                                    0\n",
       "14998                                                    0\n",
       "14999                                                    0\n",
       "Name: text, Length: 15000, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Desktop/presidentsagenda.csv')\n",
    "\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-dd3bf78871a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Get rid of all weird punctuation and extra lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-dd3bf78871a9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Get rid of all weird punctuation and extra lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "#import my csv file\n",
    "\n",
    "\n",
    "#Remove any rows with a \"nan\" in them\n",
    "df = df.dropna(axis=0, how = 'any')\n",
    "\n",
    "#Make it so that any non readable text gets converted into nothing\n",
    "#def removetext(text):\n",
    " #   return ''.join([i if ord(i) < 13 else '' for i in text])\n",
    "\n",
    "#Here I am doing the actual removing\n",
    "#df['text'] = df['text'].apply(removetext)\n",
    "\n",
    "#Make all my texts lower case\n",
    "#df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "#Get rid of all weird punctuation and extra lines\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('.',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('!',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('\"',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace(';',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('#',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace('&amp',' '))\n",
    "#df['text'] = df['text'].apply(lambda x: x.replace(',',' '))\n",
    "\n",
    "#Here I get each unique keyword from my dataframe\n",
    "#array = df['text'].str.split(' ', expand=True).stack().value_counts()\n",
    "#print(array)\n",
    "#print(array) to see what this looks like\n",
    "\n",
    "#I make a dataframe of the words and the frequency with which the words appear \n",
    "#d = {'word': array.index, 'frequency':array}\n",
    "#df2 = pd.DataFrame(data = d)\n",
    "\n",
    "#I get rid of any words that are mentioned less than 10 times\n",
    "#df2['frequency'] = df2['frequency'][df2['frequency'] > 10] \n",
    "\n",
    "#Remove any rows with a \"nan\" in them\n",
    "#df2 = df2.dropna(axis=0, how = 'any')\n",
    "\n",
    "\n",
    "#Drop any obvious signs of these words being :(\n",
    "#df2 = df2.drop([':(','https://t',':((', ':(((', ':((((', ':(((((', ':', '(', ''])\n",
    "\n",
    "#Convert my dataframe into a csv file\n",
    "#df2.to_csv('unsmile_words.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1  \\\n",
      "0  NaN  1.0   \n",
      "1  NaN  1.0   \n",
      "2  NaN  1.0   \n",
      "3  NaN  1.0   \n",
      "4  0.0  NaN   \n",
      "5  0.0  NaN   \n",
      "6  0.0  NaN   \n",
      "\n",
      "  b'RT @Conference_KCS: #YesKilifi an environment that fosters dialogue between the youth and relevant stakeholders to empower in exploring inn\\xe2\\x80\\xa6'  \\\n",
      "0  b'RT @YouthFund_Ke: #YouthEmpowermentKe\\nI urg...                                                                                                           \n",
      "1  b'RT @UKenyatta: My Administration is maximizi...                                                                                                           \n",
      "2  b'RT @kalromkulima: Having a joint discussion ...                                                                                                           \n",
      "3  b'RT @Conference_KCS: #YesKilifi an environmen...                                                                                                           \n",
      "4                                                NaN                                                                                                           \n",
      "5                                                NaN                                                                                                           \n",
      "6                                                NaN                                                                                                           \n",
      "\n",
      "  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Kenyan nightmares...  This peanut was manufactured on 30th March and today is March 20th...#worldre\\xe2\\x80\\xa6'  \n",
      "0                                                NaN                                                                                                          \n",
      "1                                                NaN                                                                                                          \n",
      "2                                                NaN                                                                                                          \n",
      "3                                                NaN                                                                                                          \n",
      "4  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
      "5  b'RT @AWfBKenya: Our chairlady @mkarembu inter...                                                                                                          \n",
      "6  b'@Robb08962871 Here is what the #Big4Agenda p...                                                                                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tech-iguana/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#import my csv files\n",
    "positives = pd.read_csv('Desktop/positives.csv')\n",
    "negatives = pd.read_csv('Desktop/negatives.csv')\n",
    "\n",
    "wordbag = pd.concat([positives, negatives]).drop_duplicates(subset = None).reset_index(drop=True)\n",
    "\n",
    "print(wordbag)\n",
    "\n",
    "wordbag.to_csv('wordbag.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Kenyan nightmares...  This peanut was manufactured on 30th March and today is March 20th...#worldre\\xe2\\x80\\xa6'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @AWfBKenya: Our chairlady @mkarembu inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @AWfBKenya: Our chairlady @mkarembu inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>b'@Robb08962871 Here is what the #Big4Agenda p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @AWfBKenya: Our chairlady @mkarembu inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @AWfBKenya: Our chairlady @mkarembu inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>b'@Robb08962871 Here is what the #Big4Agenda p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  \\\n",
       "0   0   \n",
       "1   0   \n",
       "2   0   \n",
       "3   0   \n",
       "4   0   \n",
       "5   0   \n",
       "6   0   \n",
       "7   0   \n",
       "8   0   \n",
       "9   0   \n",
       "10  0   \n",
       "11  0   \n",
       "12  0   \n",
       "13  0   \n",
       "14  0   \n",
       "15  0   \n",
       "16  0   \n",
       "17  0   \n",
       "18  0   \n",
       "\n",
       "   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Kenyan nightmares...  This peanut was manufactured on 30th March and today is March 20th...#worldre\\xe2\\x80\\xa6'  \n",
       "0   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "1   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "2   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "3   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "4   b'RT @AWfBKenya: Our chairlady @mkarembu inter...                                                                                                          \n",
       "5   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "6   b'RT @AWfBKenya: Our chairlady @mkarembu inter...                                                                                                          \n",
       "7   b'@Robb08962871 Here is what the #Big4Agenda p...                                                                                                          \n",
       "8   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "9   b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "10  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "11  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "12  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "13  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "14  b'RT @AWfBKenya: Our chairlady @mkarembu inter...                                                                                                          \n",
       "15  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          \n",
       "16  b'RT @AWfBKenya: Our chairlady @mkarembu inter...                                                                                                          \n",
       "17  b'@Robb08962871 Here is what the #Big4Agenda p...                                                                                                          \n",
       "18  b'RT @Tosh_musicmover: #SonkoHelpsTurkana Keny...                                                                                                          "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Desktop/negatives.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[', youthfund_ke:, youthempowermentke\\ni, urge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[', ukenyatta:, my, administration, is, maximi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[', ukenyatta:, my, administration, is, maximi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[', kalromkulima:, having, a, joint, discussio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[', conference_kcs:, yeskilifi, an, environmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[', youthfund_ke:, youthempowermentke\\ni, urge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[', ukenyatta:, my, administration, is, maximi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>[', ukenyatta:, my, administration, is, maximi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>[', kalromkulima:, having, a, joint, discussio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         1  [', youthfund_ke:, youthempowermentke\\ni, urge...\n",
       "1         1  [', ukenyatta:, my, administration, is, maximi...\n",
       "2         1  [', ukenyatta:, my, administration, is, maximi...\n",
       "3         1  [', kalromkulima:, having, a, joint, discussio...\n",
       "4         1  [', conference_kcs:, yeskilifi, an, environmen...\n",
       "5         1  [', youthfund_ke:, youthempowermentke\\ni, urge...\n",
       "6         1  [', ukenyatta:, my, administration, is, maximi...\n",
       "7         1  [', ukenyatta:, my, administration, is, maximi...\n",
       "8         1  [', kalromkulima:, having, a, joint, discussio..."
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Desktop/positives.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "df.columns =['polarity', 'text']\n",
    "\n",
    "#Remove any rows with a \"nan\" in them\n",
    "df = df.dropna(axis=0, how = 'any')\n",
    "\n",
    "#Make it so that any non readable text gets converted into nothing\n",
    "def removetext(text):\n",
    "    return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "#Here I am doing the actual removing\n",
    "df['text'] = df['text'].apply(removetext)\n",
    "\n",
    "#Make all my texts lower case\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "#Get rid of all weird punctuation and extra lines\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('.',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('!',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\"',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace(';',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('#',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace(',',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('@',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('rt',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('b',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('[' ' ',' '))\n",
    "\n",
    "#split all the words in my text\n",
    "df['text']= df['text'].str.split()\n",
    "\n",
    "df.to_csv('positives.csv')\n",
    "positivess = df\n",
    "positivess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[', awf, kenya:, our, chairlady, mkarem, u, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[', awf, kenya:, our, chairlady, mkarem, u, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[', ro, 08962871, here, is, what, the, ig4agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[', awf, kenya:, our, chairlady, mkarem, u, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>[', awf, kenya:, our, chairlady, mkarem, u, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>[', ro, 08962871, here, is, what, the, ig4agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>[', tosh_musicmover:, sonkohelpsturkana, kenya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    polarity                                               text\n",
       "0          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "1          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "2          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "3          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "4          0  [', awf, kenya:, our, chairlady, mkarem, u, in...\n",
       "5          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "6          0  [', awf, kenya:, our, chairlady, mkarem, u, in...\n",
       "7          0  [', ro, 08962871, here, is, what, the, ig4agen...\n",
       "8          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "9          0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "10         0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "11         0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "12         0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "13         0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "14         0  [', awf, kenya:, our, chairlady, mkarem, u, in...\n",
       "15         0  [', tosh_musicmover:, sonkohelpsturkana, kenya...\n",
       "16         0  [', awf, kenya:, our, chairlady, mkarem, u, in...\n",
       "17         0  [', ro, 08962871, here, is, what, the, ig4agen...\n",
       "18         0  [', tosh_musicmover:, sonkohelpsturkana, kenya..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Desktop/negatives.csv')\n",
    "\n",
    "df.columns =['polarity', 'text']\n",
    "\n",
    "#Remove any rows with a \"nan\" in them\n",
    "df = df.dropna(axis=0, how = 'any')\n",
    "\n",
    "#Make it so that any non readable text gets converted into nothing\n",
    "def removetext(text):\n",
    "    return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "#Here I am doing the actual removing\n",
    "df['text'] = df['text'].apply(removetext)\n",
    "\n",
    "#Make all my texts lower case\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "#Get rid of all weird punctuation and extra lines\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('.',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('!',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\"',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace(';',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('#',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace(',',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('@',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('rt',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('b',' '))\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('[' ' ',' '))\n",
    "\n",
    "#split all the words in my text\n",
    "df['text']= df['text'].str.split()\n",
    "\n",
    "df.to_csv('negatives.csv')\n",
    "negativess = df\n",
    "\n",
    "negativess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'polarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-a74a166293fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#train_positive = wordbagg['polartiy'] == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mwordbagg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#train_negative = train[wordbagg['0'] ==0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'polarity' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Read the files with the tweets\n",
    "\n",
    "\n",
    "#positivess\n",
    "#negativess\n",
    "\n",
    "\n",
    "#Join all of the dataframes into one big one for easier manipulation of a test/train split\n",
    "wordbagg = pd.concat([positivess, negativess,df]).reset_index(drop=True)\n",
    "wordbagg\n",
    "\n",
    "\n",
    "#Create a test and train set by using the sklearn function train_test_split\n",
    "train, test = train_test_split(wordbagg, test_size=0.2)\n",
    "train\n",
    "\n",
    "\n",
    "\n",
    "#train_positive = wordbagg['polartiy'] == 1\n",
    "\n",
    "wordbagg[polarity]\n",
    "#train_negative = train[wordbagg['0'] ==0]\n",
    "\n",
    "\n",
    " \n",
    "#Seperate the train data into a positive and negative set\n",
    "#train_positive = train['polarity'['1'] ==1]\n",
    "#train_negative = train['polarity'['0'] ==0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'int'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-3fe35f0ac2ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Join all of the dataframes into one big one for easier manipulation of a test/train split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositivess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegativess\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Create a test and train set by using the sklearn function train_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    287\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'int'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "#Get the wordbag\n",
    "wordbag = pd.read_csv('wordbag.csv')\n",
    "wordbag = wordbag.drop_duplicates()\n",
    "\n",
    "#Classify tweets into either positive as 1 \n",
    "#and the negatives as 0 (negative)\n",
    "positivess = 1\n",
    "negativess = 0\n",
    "\n",
    "   \n",
    "#Join all of the dataframes into one big one for easier manipulation of a test/train split\n",
    "df = pd.concat([positivess, negativess]).reset_index(drop=True)\n",
    "\n",
    "#Create a test and train set by using the sklearn function train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "#Seperate the train data into a positive and negative set\n",
    "train_positive = train[tweet['positive'] ==1]\n",
    "train_negative = train[tweet['negative'] ==0]\n",
    "\n",
    "positive_instance = len(train_positive)\n",
    "negative_instance = len(train_negative)\n",
    "print(positive_instance)\n",
    "print(negative_instance)\n",
    "\n",
    "#Create your frequency table\n",
    "frequency['word'] = wordbag['word']\n",
    "\n",
    "word_bank = [0]*len(frequency)\n",
    "positive = [0]*len(frequency)\n",
    "negative = [0]*len(frequency)\n",
    "\n",
    "#Go over all the words in the frequency table\n",
    "for i in range(len(frequency)):\n",
    "    \n",
    "    #Get the word in the frequency table at a given row\n",
    "    word = frequency['word'].iloc[i]\n",
    "    word_bank[i] = word\n",
    "             \n",
    "    #Convert the word and attached single colons ont oboth sides of the word\n",
    "    check = str(\"'\") + word + str(\"'\")\n",
    "    \n",
    "    #Count the number of instances that have the word at least once\n",
    "    count = 0  \n",
    "    \n",
    "    #this iterates through each of the tweets in the positive train set\n",
    "    for j in range(len(train_positive)):\n",
    "        #This checks to see the number of time the said word appears in a given tweet\n",
    "        appears = train_positive['text'].iloc[j].count(check)\n",
    "        \n",
    "        #If the word appears at least once, we count it as that tweet having it\n",
    "        #We sum over all the tweets that the word appears at least once in \n",
    "        if appears > 0:\n",
    "            count = count + 1\n",
    "    positive[i] = count\n",
    "            \n",
    "    #Does the same thing but for negative numbers\n",
    "    count = 0  \n",
    "    for k in range(len(train_negative)):\n",
    "        appears = train_negative['text'].iloc[k].count(check)\n",
    "        if appears > 0:\n",
    "            count = count + 1\n",
    "    negative[i] = count\n",
    "    print(i)\n",
    "\n",
    "d = {'word': word_bank, 'positive': positive, 'negative': negative}\n",
    "ftable = pd.DataFrame(data = d)\n",
    "\n",
    "ftable.to_csv('ftable.csv')\n",
    "print(positive_instance)\n",
    "print(negative_instance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftable = pd.read_csv('ftable.csv')\n",
    "ftable = ftable[ftable['word'] != 'sad']\n",
    "ftable = ftable[ftable['word'] != 'sad,']\n",
    "ftable = ftable[ftable['word'] != ':(']\n",
    "ftable = ftable[ftable['word'] != 'fun']\n",
    "ftable = ftable[ftable['word'] != 'happy,']\n",
    "ftable = ftable[ftable['word'] != 'happy']\n",
    "ftable = ftable.drop_duplicates(subset = 'word')\n",
    "\n",
    "test = 'i dont know what to do anymore'\n",
    "positive_instance = 24070.0\n",
    "negative_instance = 23930.0\n",
    "\n",
    "#split all the words in my text\n",
    "test_words = test.split()\n",
    "\n",
    "prob_positive = float(positive_instance/(positive_instance+negative_instance))\n",
    "prob_negative = 1 - prob_positive\n",
    "\n",
    "pos_word = 1.0*prob_positive\n",
    "neg_word = 1.0*prob_negative\n",
    "for i in range(len(test_words)):\n",
    "    word = test_words[i]\n",
    "    #print(word)\n",
    "    index_val = ftable.index[ftable['word'] == word]\n",
    "    if (len(index_val) > 0):\n",
    "        #print(index_val[0])\n",
    "        pos_val = ftable['positive'].iloc[index_val[0]]\n",
    "        neg_val = ftable['negative'].iloc[index_val[0]]\n",
    "        pos_word = pos_word * pos_val/positive_instance\n",
    "        neg_word = neg_word * neg_val/negative_instance\n",
    "        \n",
    "if pos_word > neg_word:\n",
    "    print(\"The sentence was POSITIVE, with a probability of\")\n",
    "    print(pos_word/(pos_word+neg_word))\n",
    "else:\n",
    "    print(\"The sentence was NEGATIVE, with a probability of\")\n",
    "    print(neg_word/(pos_word+neg_word))\n",
    "\n",
    "#print(pos_word)\n",
    "#print(neg_word)\n",
    "\n",
    "\n",
    "\n",
    "© 2019 GitHub, Inc.\n",
    "Terms\n",
    "Privacy\n",
    "Security\n",
    "Status\n",
    "Help\n",
    "Contact GitHub\n",
    "Pricing\n",
    "API\n",
    "Training\n",
    "Blog\n",
    "About\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
